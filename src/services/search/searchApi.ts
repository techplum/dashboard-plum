import { ArchiveSearchResult } from "../../types/searchAnalytics";
import { supabaseClient } from "../../utility/supabaseClient";

interface CacheEntry {
  data: ArchiveSearchResult[];
  timestamp: number;
  startDate?: string;
  endDate?: string;
}

let searchAnalyticsCache: CacheEntry | null = null;
const CACHE_DURATION = 5 * 60 * 1000; // 5 minutes
const PAGE_SIZE = 1000; // Taille de la page (peut √™tre r√©duite si n√©cessaire)

// Fonctions de validation du cache
const isCacheExpired = (cache: CacheEntry | null): boolean => {
  return !cache || Date.now() - cache.timestamp >= CACHE_DURATION;
};

const isCacheEmpty = (cache: CacheEntry | null): boolean => {
  return !cache || cache.data.length === 0;
};

const areDatesInCache = (startDate: string, endDate: string, cache: CacheEntry | null): boolean => {
  if (!cache || cache.data.length === 0) return false;

  const requestStart = new Date(`${startDate}T00:00:00`);
  const requestEnd = new Date(`${endDate}T23:59:59`);

  const cacheDates = cache.data
    .map(item => new Date(item.created_at!))
    .filter(date => !isNaN(date.getTime()));

  if (cacheDates.length === 0) return false;

  const cacheStart = new Date(Math.min(...cacheDates.map(date => date.getTime())));
  const cacheEnd = new Date(Math.max(...cacheDates.map(date => date.getTime())));

  return cacheStart <= requestStart && cacheEnd >= requestEnd;
};

const validateCache = (startDate?: string, endDate?: string): boolean => {
  if (isCacheExpired(searchAnalyticsCache)) {
    console.log('Cache expir√©');
    return false;
  }

  if (isCacheEmpty(searchAnalyticsCache)) {
    console.log('Cache vide');
    return false;
  }

  if (!startDate || !endDate) {
    console.log('Pas de dates sp√©cifi√©es, cache valide');
    return true;
  }

  const datesInCache = areDatesInCache(startDate, endDate, searchAnalyticsCache);
  if (!datesInCache) {
    console.log('Dates non pr√©sentes dans le cache');
    return false;
  }

  console.log('Cache valide');
  return true;
};

// Fonction pour r√©cup√©rer les donn√©es avec filtrage par date
const fetchDataForPeriod = async (
  startDate: string,
  endDate: string,
  limit: number = PAGE_SIZE // Limite le nombre de r√©sultats
): Promise<ArchiveSearchResult[]> => {
  const { data, error } = await supabaseClient
    .from('archive_search_results')
    .select('*')
    .gte('created_at', `${startDate}T00:00:00`)
    .lte('created_at', `${endDate}T23:59:59`)
    .order('created_at', { ascending: true })
    .limit(limit); // Limite le nombre de r√©sultats r√©cup√©r√©s

  if (error) {
    console.error("Erreur lors de la r√©cup√©ration des donn√©es:", error);
    throw error;
  }

  console.log(`Donn√©es r√©cup√©r√©es : ${data?.length || 0} r√©sultats`);
  return data || [];
};

// Fonction pour r√©cup√©rer uniquement les dates pour une p√©riode avec pagination compl√®te
const fetchDatesForPeriod = async (
  startDate: string,
  endDate: string,
  maxLimit: number = 50000 // Limite maximale de s√©curit√©
): Promise<Date[]> => {
  let allDates: Date[] = [];
  let currentPage = 0;
  let hasMoreData = true;
  const pageSize = 1000; // Taille de page Supabase
  const maxPages = Math.ceil(maxLimit / pageSize);

  console.log(`üîç D√©but de r√©cup√©ration pagin√©e des recherches pour ${startDate} √† ${endDate}`);

  while (hasMoreData && currentPage < maxPages) {
    try {
      const startRange = currentPage * pageSize;
      const endRange = (currentPage + 1) * pageSize - 1;
      
      console.log(`üìÑ R√©cup√©ration page ${currentPage + 1} des recherches (range: ${startRange}-${endRange})`);

      const { data, error, count } = await supabaseClient
        .from('archive_search_results')
        .select('created_at', { count: 'exact' })
        .gte('created_at', `${startDate}T00:00:00`)
        .lte('created_at', `${endDate}T23:59:59`)
        .order('created_at', { ascending: true })
        .range(startRange, endRange);

      if (error) {
        console.error("‚ùå Erreur lors de la r√©cup√©ration des dates:", error);
        throw error;
      }

      // Log pour la premi√®re page
      if (currentPage === 0 && count !== null) {
        console.log(`üìä Total estim√© de recherches dans la p√©riode: ${count}`);
        console.log(`üìà Nombre de pages attendues: ${Math.ceil(count / pageSize)}`);
      }

      if (!data || data.length === 0) {
        console.log(`‚ö†Ô∏è Aucune donn√©e pour la page ${currentPage + 1}`);
        break;
      }

      const validDates = data
        .map(item => new Date(item.created_at))
        .filter(date => !isNaN(date.getTime()));

      allDates = [...allDates, ...validDates];
      currentPage++;

      console.log(`‚úÖ Page ${currentPage} r√©cup√©r√©e: ${validDates.length} recherches valides`);

      // Condition d'arr√™t
      if (data.length < pageSize) {
        console.log(`üèÅ Fin de pagination recherches: derni√®re page avec ${data.length} r√©sultats`);
        hasMoreData = false;
      }

    } catch (error) {
      console.error(`‚ùå Erreur lors de la r√©cup√©ration de la page ${currentPage + 1}:`, error);
      throw error;
    }
  }

  if (currentPage >= maxPages) {
    console.warn(`‚ö†Ô∏è Limite de s√©curit√© atteinte pour les recherches (${maxPages} pages)`);
  }

  console.log(`üéâ R√©cup√©ration recherches termin√©e: ${allDates.length} recherches sur ${currentPage} pages`);
  return allDates;
};

// Fonction pour r√©cup√©rer toutes les donn√©es (avec une limite)
const fetchAllData = async (limit: number = PAGE_SIZE): Promise<ArchiveSearchResult[]> => {
  const { data, error } = await supabaseClient
    .from('archive_search_results')
    .select('*')
    .order('created_at', { ascending: true })
    .limit(limit); // Limite le nombre de r√©sultats r√©cup√©r√©s

  if (error) {
    console.error("Erreur lors de la r√©cup√©ration des donn√©es:", error);
    throw error;
  }

  console.log(`Donn√©es r√©cup√©r√©es : ${data?.length || 0} r√©sultats`);
  return data || [];
};

// Export des fonctions principales
export const fetchSearchAnalytics = async (
  startDate: string,
  endDate: string,
  limit: number = PAGE_SIZE // Limite le nombre de r√©sultats
): Promise<ArchiveSearchResult[]> => {
  console.log("Appel de fetchSearchAnalytics");

  if (validateCache(startDate, endDate) && searchAnalyticsCache) {
    console.log('Utilisation du cache');
    return searchAnalyticsCache.data
      .filter(item => {
        const itemDate = new Date(item.created_at!);
        return itemDate >= new Date(`${startDate}T00:00:00`) && 
               itemDate <= new Date(`${endDate}T23:59:59`);
      })
      .slice(0, limit); // Limite les r√©sultats retourn√©s
  }

  const data = await fetchDataForPeriod(startDate, endDate, limit);
  
  searchAnalyticsCache = {
    data,
    timestamp: Date.now(),
    startDate,
    endDate
  };

  return data;
};

export const fetchAllSearch = async (
  limit: number = PAGE_SIZE // Limite le nombre de r√©sultats
): Promise<ArchiveSearchResult[]> => {
  console.log("Appel de fetchAllSearch");

  if (validateCache() && searchAnalyticsCache) {
    console.log('Utilisation du cache pour toutes les donn√©es');
    return searchAnalyticsCache.data.slice(0, limit); // Limite les r√©sultats retourn√©s
  }

  const data = await fetchAllData(limit);
  
  searchAnalyticsCache = {
    data,
    timestamp: Date.now()
  };

  return data;
};

export const fetchSearchAnalyticsByPeriod = async (
  startDate: string,
  endDate: string
): Promise<Date[]> => {
  console.log("Appel de fetchSearchAnalyticsByPeriod");

  if (validateCache(startDate, endDate) && searchAnalyticsCache) {
    console.log('Utilisation du cache pour les recherches');
    return searchAnalyticsCache.data
      .filter(item => {
        const itemDate = new Date(item.created_at!);
        return itemDate >= new Date(`${startDate}T00:00:00`) && 
               itemDate <= new Date(`${endDate}T23:59:59`);
      })
      .map(item => new Date(item.created_at!))
      .filter(date => !isNaN(date.getTime()));
  }

  // R√©cup√©rer toutes les donn√©es avec pagination (pas de limite artificielle)
  return fetchDatesForPeriod(startDate, endDate);
};